experimentName: astnn_codebert_attention_filter
#experimentWorkingDirectory: xxx
searchSpace:
#  batch_size:
#    _type: choice
#    _value: [ 1, 2, 4, 8, 16, 32, 64, 128 ]
#  lr:
#    _type: choice
#    _value: [ 0.005, 0.001, 0.0005, 0.0001 ]
#  hidden_size: # 图卷积层大小
#    _type: choice
#    _value: [ 1024, 768, 512, 256 ]
  attention_heads: # 图卷积层注意力机制 head
    _type: choice
    _value: [ 2, 4, 8, 12, 16 ]
#  dropout:
#    _type: choice
#    _value: [ 0,1, 0,2, 0,3, 0.4, 0,5 ]
#  epochs:
#    _type: choice
#    _value: [ 100 ]
  num_layers: # 图卷积层数
    _type: choice
    _value: [ 1, 2, 3, 4, 5 ]
  approach:
    _type: choice
    _value: ['attention', 'wo_concat', 'wo_attention']
  embedding_type:
    _type: choice
    _value: ['astnn+codebert', 'astnn', 'codebert']

debug: True
trialCommand: python3.9 astnn+codebert_embedding.py --nni True --gpu 0 --step 1 --concurrency True
trialCodeDirectory: .
trialGpuNumber: 1
maxTrialNumber: 225
trialConcurrency: 8 # 同时执行几个任务
tunerGpuIndices: [ 6, 7, 8, 9 ]

tuner:
  name: Random
  class_args:
    seed: 5
#tuner:
#  name: TPE
#  classArgs:
#    optimizeMode: maximize
trainingService:
  platform: local
  maxTrialNumberPerGpu: 3
  gpuIndices: [ 6, 7, 8, 9 ]
  useActiveGpu: true

# nnictl create --config config.yml --port 8080
# ssh -N -f -L 8080:127.0.0.1:8080 shunliu@115.236.33.122 -p 9998 -i
# -N: 此选项告诉 SSH 不要执行远程命令。它在你只想转发端口时非常有用。
# -f: 此选项告诉 SSH 在命令执行之前转入后台运行。这样可以在后台运行隧道。
# -L 8080:127.0.0.1:8080: 此选项指定本地端口转发。它将本地机器上的端口 8080 转发到远程地址 127.0.0.1 的端口 8080。